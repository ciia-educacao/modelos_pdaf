{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O presente notebook aborda o problema de **detecção de fraudes em transações financeiras**. Cada linha da base representa uma transação feita com cartão de crédito, contendo informações como data, valor, localização, estabelecimento, e um campo binário (`is_fraud`) que indica se a transação foi fraudulenta ou não.\n",
    "\n",
    "Para a tarefa de classificação, foi utilizado o algoritmo **Isolation Forest**, um método não supervisionado especialmente eficaz para detecção de anomalias (outliers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "| Biblioteca / Módulo                        | Descrição                                                                 |\n",
    "|-------------------------------------------|---------------------------------------------------------------------------|\n",
    "| `pandas` (`pd`)                           | Utilizada para manipulação e análise de dados em forma de tabelas (DataFrames). |\n",
    "| `sklearn.model_selection.train_test_split` | Função para dividir o conjunto de dados em treino e teste.                |\n",
    "| `sklearn.preprocessing.OneHotEncoder`     | Codifica variáveis categóricas em vetores binários (one-hot encoding).    |\n",
    "| `sklearn.compose.ColumnTransformer`       | Permite aplicar diferentes transformações a diferentes colunas do DataFrame. |\n",
    "| `sklearn.pipeline.Pipeline`               | Cria um fluxo de processamento com etapas sequenciais (ex: pré-processamento + modelo). |\n",
    "| `sklearn.ensemble.RandomForestClassifier` | Algoritmo de aprendizado de máquina baseado em múltiplas árvores de decisão para classificação. |\n",
    "| `sklearn.ensemble.IsolationForest`        | Algoritmo para detecção de anomalias baseado em árvores (unsupervised).   |\n",
    "| `numpy` (`np`)                            | Biblioteca para computação numérica e manipulação de arrays.              |\n",
    "| `sklearn.metrics.*`                       | Conjunto de funções para avaliação de modelos (ex: accuracy, F1, ROC AUC, etc.). |\n",
    "| `matplotlib.pyplot` (`plt`)               | Biblioteca para criação de gráficos e visualizações.                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-30T18:16:54.655235Z",
     "iopub.status.busy": "2025-06-30T18:16:54.654976Z",
     "iopub.status.idle": "2025-06-30T18:16:58.709904Z",
     "shell.execute_reply": "2025-06-30T18:16:58.709007Z",
     "shell.execute_reply.started": "2025-06-30T18:16:54.655212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição das Colunas da Base de Dados\n",
    "\n",
    "| Coluna                 | Descrição                                                                 |\n",
    "|------------------------|---------------------------------------------------------------------------|\n",
    "| `Unnamed: 0`           | Índice original do dataset                                                |\n",
    "| `trans_date_trans_time` | Data e hora da transação.                                                |\n",
    "| `cc_num`               | Número do cartão de crédito (anonimizado).                                |\n",
    "| `merchant`             | Nome do comerciante onde a transação ocorreu.                             |\n",
    "| `category`             | Categoria do comerciante (ex: food, gas_transport, etc).                  |\n",
    "| `amt`                  | Valor da transação em dólares.                                            |\n",
    "| `first`                | Primeiro nome do titular do cartão.                                       |\n",
    "| `last`                 | Sobrenome do titular do cartão.                                           |\n",
    "| `gender`               | Gênero do titular do cartão (`M` ou `F`).                                 |\n",
    "| `street`               | Endereço residencial do titular do cartão.                                |\n",
    "| `lat`                  | Latitude da residência do titular do cartão.                              |\n",
    "| `long`                 | Longitude da residência do titular do cartão.                             |\n",
    "| `city_pop`             | População estimada da cidade de residência.                               |\n",
    "| `job`                  | Profissão do titular do cartão.                                           |\n",
    "| `dob`                  | Data de nascimento do titular do cartão.                                  |\n",
    "| `trans_num`            | Identificador único da transação.                                         |\n",
    "| `unix_time`            | Timestamp UNIX da transação.                                              |\n",
    "| `merch_lat`            | Latitude do comerciante.                                                  |\n",
    "| `merch_long`           | Longitude do comerciante.                                                 |\n",
    "| `is_fraud`             | Indicador de fraude (`1` para fraude, `0` para legítima).                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:16:58.712696Z",
     "iopub.status.busy": "2025-06-30T18:16:58.712218Z",
     "iopub.status.idle": "2025-06-30T18:17:11.310898Z",
     "shell.execute_reply": "2025-06-30T18:17:11.309530Z",
     "shell.execute_reply.started": "2025-06-30T18:16:58.712664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importação e visualização das colunas\n",
    "dataframe = pd.read_csv('/kaggle/input/fraud-detection/fraudTrain.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização de dados relevantes\n",
    "\n",
    "1. Transformar datas em  conjuntos de objetos em formato datetime.\n",
    "2. Organização de transações por cartões, em seguida, calcula a diferença de tempo entre cada transação.\n",
    "3. Remove colunas irrelevantes.\n",
    "4. Categorizando colunas em classes `Numéricas` e `Categóricas`.\n",
    "\n",
    "### Separação da Variável `X`\n",
    "\n",
    "| Variável | Conteúdo                              | Função no Modelo                                |\n",
    "|----------|----------------------------------------|--------------------------------------------------|\n",
    "| `X`      | Todas as colunas independentes do DataFrame (features) que serão usadas para encontrar anomalias. A variável alvo (target_col, como is_fraud) não é incluída para o treinamento. | Usada como entrada para o treinamento do Isolation Forest, que aprende a identificar desvios nos dados. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:17:11.314785Z",
     "iopub.status.busy": "2025-06-30T18:17:11.314508Z",
     "iopub.status.idle": "2025-06-30T18:17:11.789085Z",
     "shell.execute_reply": "2025-06-30T18:17:11.787816Z",
     "shell.execute_reply.started": "2025-06-30T18:17:11.314734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Datas para Objetos Datetimes\n",
    "dataframe['trans_date_trans_time'] = pd.to_datetime(dataframe['trans_date_trans_time'])\n",
    "dataframe['hour_of_day'] = dataframe['trans_date_trans_time'].dt.hour\n",
    "dataframe['day_of_week'] = dataframe['trans_date_trans_time'].dt.dayofweek\n",
    "dataframe['month'] = dataframe['trans_date_trans_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:17:11.790621Z",
     "iopub.status.busy": "2025-06-30T18:17:11.790305Z",
     "iopub.status.idle": "2025-06-30T18:17:13.874694Z",
     "shell.execute_reply": "2025-06-30T18:17:13.873724Z",
     "shell.execute_reply.started": "2025-06-30T18:17:11.790592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diferença de tempo entre transações.\n",
    "dataframe = dataframe.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
    "dataframe['time_since_last_transaction'] = dataframe.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:17:13.876005Z",
     "iopub.status.busy": "2025-06-30T18:17:13.875657Z",
     "iopub.status.idle": "2025-06-30T18:17:15.533525Z",
     "shell.execute_reply": "2025-06-30T18:17:15.532598Z",
     "shell.execute_reply.started": "2025-06-30T18:17:13.875979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definir coluna label (Será usada para testar os resultados gerado pelo Modelo)\n",
    "target_col = 'is_fraud'\n",
    "\n",
    "# Remover colunas irrelevantes e label dos dados\n",
    "columns_to_drop_final = ['Unnamed: 0', 'trans_num', 'first', 'last', 'street', 'city', 'zip', 'dob', 'ssn']\n",
    "df_processed = dataframe.drop(columns=columns_to_drop_final, errors='ignore').copy()\n",
    "\n",
    "# Separar X e y\n",
    "X = df_processed.drop(columns=[target_col], errors='ignore')\n",
    "y = df_processed[target_col]\n",
    "\n",
    "# Definir colunas numéricas e categóricas\n",
    "numerical_cols = ['amt', 'lat', 'long', 'city_pop', 'unix_time',\n",
    "                  'time_since_last_transaction', 'merch_lat', 'merch_long']\n",
    "categorical_cols = ['category', 'gender', 'state', 'job', 'merchant']\n",
    "\n",
    "# Dividir conjunto de dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "1. Pré-Processamento de dados para o modelo usar de forma eficiente as classes `numéricas` e `categóricas`\n",
    "2. Separação de treino e testes. Neste caso, foi utilizado 80% dos dados para testes e 20% para validações do modelo.\n",
    "3. Treinamento do modelo utilizando o modelo Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:17:15.536373Z",
     "iopub.status.busy": "2025-06-30T18:17:15.535947Z",
     "iopub.status.idle": "2025-06-30T18:17:49.501579Z",
     "shell.execute_reply": "2025-06-30T18:17:49.500811Z",
     "shell.execute_reply.started": "2025-06-30T18:17:15.536339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculo de contaminação\n",
    "fraud_ratio = y_train.sum() / len(y_train)\n",
    "contamination_rate = max(fraud_ratio, 0.01)\n",
    "\n",
    "# Preprocessamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Treinamento do Modelo\n",
    "iso_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('anomaly_detector', IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination=contamination_rate,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "iso_pipeline.fit(X_train)\n",
    "\n",
    "# Classificando de acordo com o modelo\n",
    "X_test_preprocessed = iso_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "anomaly_scores = -iso_pipeline.named_steps['anomaly_detector'].decision_function(X_test_preprocessed)\n",
    "\n",
    "# Ajuste de limite (threshold)\n",
    "threshold = np.percentile(anomaly_scores, 99.5)\n",
    "iso_predictions = (anomaly_scores >= threshold).astype(int)\n",
    "iso_predictions = 1 - iso_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T18:17:49.502777Z",
     "iopub.status.busy": "2025-06-30T18:17:49.502505Z",
     "iopub.status.idle": "2025-06-30T18:17:57.978036Z",
     "shell.execute_reply": "2025-06-30T18:17:57.977130Z",
     "shell.execute_reply.started": "2025-06-30T18:17:49.502755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Avaliação do Modelo\n",
    "print(\"\\nRelatório de Classificação (Isolation Forest):\\n\",\n",
    "      classification_report(y_test, iso_predictions, target_names=['Não Fraude', 'Fraude']))\n",
    "\n",
    "# Métricas\n",
    "accuracy_iso = accuracy_score(y_test, iso_predictions)\n",
    "precision_iso = precision_score(y_test, iso_predictions, pos_label=1)\n",
    "recall_iso = recall_score(y_test, iso_predictions, pos_label=1)\n",
    "f1_iso = f1_score(y_test, iso_predictions, pos_label=1)\n",
    "\n",
    "iso_anomaly_scores = -iso_pipeline.named_steps['anomaly_detector'].decision_function(\n",
    "    iso_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    ")\n",
    "\n",
    "scaled_scores = MinMaxScaler().fit_transform(iso_anomaly_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "roc_auc_iso = roc_auc_score(y_test, scaled_scores)\n",
    "pr_auc_iso = average_precision_score(y_test, scaled_scores)\n",
    "\n",
    "# Impressão dos resultados\n",
    "print(f\"Acurácia: {accuracy_iso:.4f}\")\n",
    "print(f\"Precisão (Fraude): {precision_iso:.4f}\")\n",
    "print(f\"Recall (Fraude): {recall_iso:.4f}\")\n",
    "print(f\"F1-Score (Fraude): {f1_iso:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_iso:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_iso:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão do Modelo Inicial Isolation Forest\n",
    "\n",
    "# Análise dos Resultados:\n",
    "\n",
    "O modelo de Isolation Forest apresenta uma acurácia extremamente baixa (1.04%). Entretanto:\n",
    "\n",
    "1. A base é altamente desbalanceada: menos de 1% são fraudes.\n",
    "\n",
    "2. A precisão (0.56%) para fraude é péssimo, pois o modelo praticamente não acerta, logo, quando ele diz que é fraude, geralmente está errado.\n",
    "\n",
    "3. O Recall (97.07%) para fraude é excelente: Este é o único ponto positivo notável do modelo. Um recall de 97.07% indica que o modelo consegue identificar quase todas as fraudes reais. Ele é muito bom em \"pegar\" as fraudes que realmente existem. No entanto, este alto recall vem à custa de uma precisão extremamente baixa, como vimos acima.\n",
    "\n",
    "4. F1-Score (0.011%) para fraude é muito baixo.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 817870,
     "sourceId": 1399887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
