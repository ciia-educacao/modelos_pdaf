{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O presente notebook aborda o problema de **detecção de fraudes em transações financeiras**. Cada linha da base representa uma transação feita com cartão de crédito, contendo informações como data, valor, localização, estabelecimento, e um campo binário (`is_fraud`) que indica se a transação foi fraudulenta ou não.\n",
    "\n",
    "Para a tarefa de classificação, foi utilizado uma abordagem híbrida dos algoritmos **Random Forest** e **Isolation Forest**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "| Biblioteca / Módulo                        | Descrição                                                                 |\n",
    "|-------------------------------------------|---------------------------------------------------------------------------|\n",
    "| `pandas` (`pd`)                           | Utilizada para manipulação e análise de dados em forma de tabelas (DataFrames). |\n",
    "| `sklearn.model_selection.train_test_split` | Função para dividir o conjunto de dados em treino e teste.                |\n",
    "| `sklearn.preprocessing.OneHotEncoder`     | Codifica variáveis categóricas em vetores binários (one-hot encoding).    |\n",
    "| `sklearn.compose.ColumnTransformer`       | Permite aplicar diferentes transformações a diferentes colunas do DataFrame. |\n",
    "| `sklearn.pipeline.Pipeline`               | Cria um fluxo de processamento com etapas sequenciais (ex: pré-processamento + modelo). |\n",
    "| `sklearn.ensemble.RandomForestClassifier` | Algoritmo de aprendizado de máquina baseado em múltiplas árvores de decisão para classificação. |\n",
    "| `sklearn.ensemble.IsolationForest`        | Algoritmo para detecção de anomalias baseado em árvores (unsupervised).   |\n",
    "| `numpy` (`np`)                            | Biblioteca para computação numérica e manipulação de arrays.              |\n",
    "| `sklearn.metrics.*`                       | Conjunto de funções para avaliação de modelos (ex: accuracy, F1, ROC AUC, etc.). |\n",
    "| `matplotlib.pyplot` (`plt`)               | Biblioteca para criação de gráficos e visualizações.                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T15:17:22.852082Z",
     "iopub.status.busy": "2025-06-24T15:17:22.851782Z",
     "iopub.status.idle": "2025-06-24T15:17:22.857737Z",
     "shell.execute_reply": "2025-06-24T15:17:22.85683Z",
     "shell.execute_reply.started": "2025-06-24T15:17:22.852062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Manipulação de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pré-processamento e transformação\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "# Modelos\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Divisão dos dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Métricas de avaliação\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "# Visualização opcional (se quiser ver distribuição dos scores)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição das Colunas da Base de Dados\n",
    "\n",
    "| Coluna                 | Descrição                                                                 |\n",
    "|------------------------|---------------------------------------------------------------------------|\n",
    "| `Unnamed: 0`           | Índice original do dataset                                                |\n",
    "| `trans_date_trans_time` | Data e hora da transação.                                                |\n",
    "| `cc_num`               | Número do cartão de crédito (anonimizado).                                |\n",
    "| `merchant`             | Nome do comerciante onde a transação ocorreu.                             |\n",
    "| `category`             | Categoria do comerciante (ex: food, gas_transport, etc).                  |\n",
    "| `amt`                  | Valor da transação em dólares.                                            |\n",
    "| `first`                | Primeiro nome do titular do cartão.                                       |\n",
    "| `last`                 | Sobrenome do titular do cartão.                                           |\n",
    "| `gender`               | Gênero do titular do cartão (`M` ou `F`).                                 |\n",
    "| `street`               | Endereço residencial do titular do cartão.                                |\n",
    "| `lat`                  | Latitude da residência do titular do cartão.                              |\n",
    "| `long`                 | Longitude da residência do titular do cartão.                             |\n",
    "| `city_pop`             | População estimada da cidade de residência.                               |\n",
    "| `job`                  | Profissão do titular do cartão.                                           |\n",
    "| `dob`                  | Data de nascimento do titular do cartão.                                  |\n",
    "| `trans_num`            | Identificador único da transação.                                         |\n",
    "| `unix_time`            | Timestamp UNIX da transação.                                              |\n",
    "| `merch_lat`            | Latitude do comerciante.                                                  |\n",
    "| `merch_long`           | Longitude do comerciante.                                                 |\n",
    "| `is_fraud`             | Indicador de fraude (`1` para fraude, `0` para legítima).                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T15:17:22.86806Z",
     "iopub.status.busy": "2025-06-24T15:17:22.867426Z",
     "iopub.status.idle": "2025-06-24T15:17:31.886908Z",
     "shell.execute_reply": "2025-06-24T15:17:31.88577Z",
     "shell.execute_reply.started": "2025-06-24T15:17:22.868025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importação e visualização das colunas\n",
    "dataframe = pd.read_csv('/kaggle/input/fraud-detection/fraudTrain.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização de dados relevantes\n",
    "\n",
    "1. Transformar datas em  conjuntos de objetos em formato datetime.\n",
    "2. Organização de transações por cartões, em seguida, calcula a diferença de tempo entre cada transação.\n",
    "3. Remove colunas irrelevantes, definir coluna de label `is_fraud`, e remover a coluna label dos dados que serão usados no treinamento.\n",
    "4. Categorizando colunas em classes `Numéricas` e `Categóricas`.\n",
    "\n",
    "### Separação de Variáveis: `X` e `y`\n",
    "\n",
    "| Variável | Conteúdo                              | Função no Modelo                                |\n",
    "|----------|----------------------------------------|--------------------------------------------------|\n",
    "| `X`      | Todas as colunas **independentes** do DataFrame (features), exceto a variável alvo (`target_col`). | Usada como entrada para o treinamento e predição. |\n",
    "| `y`      | Coluna **alvo** (`target_col`) do DataFrame, contendo os rótulos (ex: `is_fraud`). | Usada como saída esperada no treinamento (o que o modelo tenta prever). |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T15:17:31.88868Z",
     "iopub.status.busy": "2025-06-24T15:17:31.888399Z",
     "iopub.status.idle": "2025-06-24T15:17:32.349605Z",
     "shell.execute_reply": "2025-06-24T15:17:32.348545Z",
     "shell.execute_reply.started": "2025-06-24T15:17:31.88866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Datas para Objetos Datetimes\n",
    "dataframe['trans_date_trans_time'] = pd.to_datetime(dataframe['trans_date_trans_time'])\n",
    "dataframe['hour_of_day'] = dataframe['trans_date_trans_time'].dt.hour\n",
    "dataframe['day_of_week'] = dataframe['trans_date_trans_time'].dt.dayofweek\n",
    "dataframe['month'] = dataframe['trans_date_trans_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T15:17:32.350613Z",
     "iopub.status.busy": "2025-06-24T15:17:32.350307Z",
     "iopub.status.idle": "2025-06-24T15:17:34.31737Z",
     "shell.execute_reply": "2025-06-24T15:17:34.316468Z",
     "shell.execute_reply.started": "2025-06-24T15:17:32.350588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diferença de tempo entre transações.\n",
    "dataframe = dataframe.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
    "dataframe['time_since_last_transaction'] = dataframe.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T15:18:16.136799Z",
     "iopub.status.busy": "2025-06-24T15:18:16.136476Z",
     "iopub.status.idle": "2025-06-24T15:18:16.669735Z",
     "shell.execute_reply": "2025-06-24T15:18:16.668877Z",
     "shell.execute_reply.started": "2025-06-24T15:18:16.136779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Definir coluna label\n",
    "target_col = 'is_fraud'\n",
    "# Removendo colunas irrelevantes e coluna label dos dados de treinamento\n",
    "columns_to_drop_final = ['Unnamed: 0', 'trans_num', 'first', 'last', 'street', 'city', 'zip', 'dob', 'ssn']\n",
    "df_processed = dataframe.drop(columns=columns_to_drop_final, errors='ignore').copy()\n",
    "X = df_processed.drop(columns=[target_col], errors='ignore')\n",
    "y = df_processed[target_col]\n",
    "# Categorização de colunas\n",
    "numerical_cols = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'time_since_last_transaction', 'merch_lat', 'merch_long']\n",
    "categorical_cols = ['category', 'gender', 'state', 'job', 'merchant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "1. Pré-Processamento de dados para o modelo usar de forma eficiente as classes `numéricas` e `categóricas`\n",
    "2. Separação de treino e testes. Neste caso, foi utilizado 80% dos dados para testes e 20% para validações do modelo.\n",
    "3. Filtragem de dados com Isolation Forest.\n",
    "5. Treinamento do modelo utilizando o modelo Random Forest com os dados pré-filtrados pelo IF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T15:18:34.994173Z",
     "iopub.status.busy": "2025-06-24T15:18:34.993884Z",
     "iopub.status.idle": "2025-06-24T15:26:52.951015Z",
     "shell.execute_reply": "2025-06-24T15:26:52.9498Z",
     "shell.execute_reply.started": "2025-06-24T15:18:34.994154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Separar treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Pré-filtragem com Isolation Forest\n",
    "iso = IsolationForest(n_estimators=100, contamination=0.01, random_state=42, n_jobs=-1)\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "iso.fit(X_train_proc)\n",
    "\n",
    "# Aplicar no conjunto de teste\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "anomaly_scores = -iso.decision_function(X_test_proc)\n",
    "\n",
    "# Selecionar apenas os mais anômalos\n",
    "threshold = np.percentile(anomaly_scores, 90)\n",
    "mask_suspects = anomaly_scores >= threshold\n",
    "\n",
    "# Filtrar para Random Forest\n",
    "X_test_suspects = X_test[mask_suspects]\n",
    "y_test_suspects = y_test[mask_suspects]\n",
    "\n",
    "# Treinar Random Forest no conjunto completo (poderia ser refinado também)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar RF apenas nos casos suspeitos\n",
    "\n",
    "rf_predictions = rf_pipeline.predict(X_test_suspects)\n",
    "rf_probabilities = rf_pipeline.predict_proba(X_test_suspects)[:, 1]\n",
    "rf_predictions = (rf_probabilities >= 0.3).astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T16:19:57.823951Z",
     "iopub.status.busy": "2025-06-24T16:19:57.823624Z",
     "iopub.status.idle": "2025-06-24T16:19:58.443329Z",
     "shell.execute_reply": "2025-06-24T16:19:58.442193Z",
     "shell.execute_reply.started": "2025-06-24T16:19:57.823929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Avaliação\n",
    "print(\"\\nAvaliação apenas nos casos suspeitos (filtrados pelo Isolation Forest):\")\n",
    "print(classification_report(y_test_suspects, rf_predictions, target_names=['Não Fraude', 'Fraude']))\n",
    "\n",
    "accuracy = accuracy_score(y_test_suspects, rf_predictions)\n",
    "precision = precision_score(y_test_suspects, rf_predictions, pos_label=1)\n",
    "recall = recall_score(y_test_suspects, rf_predictions, pos_label=1)\n",
    "f1 = f1_score(y_test_suspects, rf_predictions, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test_suspects, rf_probabilities)\n",
    "pr_auc = average_precision_score(y_test_suspects, rf_probabilities)\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão (Fraude): {precision:.4f}\")\n",
    "print(f\"Recall (Fraude): {recall:.4f}\")\n",
    "print(f\"F1-Score (Fraude): {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão do Modelo Híbrido: Isolation Forest + Random Forest\n",
    "\n",
    "#### Análise dos Resultados:\n",
    "\n",
    "A abordagem híbrida combina um filtro inicial por anomalias (Isolation Forest) com um classificador supervisionado (Random Forest) para refinar os casos suspeitos. Nos dados analisados:\n",
    "\n",
    "1. A acurácia foi de 99,37%, e o F1-Score para fraude alcançou 82,99% **dentro do subconjunto de transações suspeitas**.\n",
    "\n",
    "2. O modelo demonstrou bom desempenho interno: das 238 fraudes detectadas, 84,03% foram corretamente identificadas, com 81,97% de precisão.\n",
    "\n",
    "3. **No entanto, apenas 238 das 1.501 fraudes reais foram analisadas**, o que representa **apenas 15,85% do total de fraudes**. Isso significa que cerca de **84% das fraudes reais foram perdidas já na etapa de filtragem pelo Isolation Forest**."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 817870,
     "sourceId": 1399887,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
